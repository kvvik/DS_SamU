{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1516e1b",
   "metadata": {},
   "source": [
    "# Логгирование экспериментов\n",
    "Для исследователей крайне важно содержать в чистоте результаты экспериментов, ведь в случаях поиска архитектур, гиперпараметров и т.д. может быть воспроизведено большое множество экспериментов. В случае если число проведенных экспериментов переваливает за десятки - становится крайне сложно следить за результатами и производить перекрестное сравнение, находить ошибки, выбирать лучший вариант. \n",
    "\n",
    "Для борьбы с выше перечисленными проблемами созданы инструменты логгирования и агрегирования экспериментов такие как:\n",
    " * [`weights and biases`](https://wandb.ai/site)\n",
    " * [`mlflow`](https://mlflow.org/)\n",
    " * [`comet.ml`](https://www.comet.ml/)\n",
    " * [`Tensorboard`](https://www.tensorflow.org/tensorboard)\n",
    " \n",
    "Большинство из данынх инструментов распространяются на платной основе. Однако чаще всего студенты могут получит полный доступ к инструменту зарегестрировавшись по почте с доменом университета или используя github аккаунт подтвержденый в github-students.\n",
    "\n",
    "В настоящем руководстве будет рассмотрен только инструмент `comet.ml`. Он полностью бесплатен в случае если вы собираете использовать его функционал единолично.\n",
    "\n",
    "Для использования `comet.ml` необходимо установить пакет `comet-ml`\n",
    "\n",
    "`pip install comet-ml==3.26.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b914aa8",
   "metadata": {},
   "source": [
    "## Comet.ml в `Pytorch`\n",
    "Возьмем в качестве исходного кода - код используемый в файле `pytorch_basics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283dc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "954487dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e93eca",
   "metadata": {},
   "source": [
    "Создадим объект эксперимента.\n",
    "\n",
    "Для его создания нужно иметь `API_KEY` который **можно получить в ЛК comet.ml**\n",
    "\n",
    "Данный объект имеет большой набор параметров, о которых вы можете узнать из документации однако нас устроят и стандартные значения параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    api_key='***',\n",
    "    project_name='pytorch_cometml_lightning',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd985a",
   "metadata": {},
   "source": [
    "### Назавние эксперимента и теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ec57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_name(\"Testing comet.ml logging\")\n",
    "experiment.add_tag(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66dff0",
   "metadata": {},
   "source": [
    "Создав объект эксперимента он сразу появится в comet.ml в соответствующем проекте. \n",
    "\n",
    "![Overview](./imgs/overivew.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7eb349",
   "metadata": {},
   "source": [
    "### Логгирование гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca221cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 1024,\n",
    "    \"num_workers\": 4,\n",
    "    \"in_channels\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278b765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143c908",
   "metadata": {},
   "source": [
    "Выполнив метод выше мы можем увидеть, что переданные гиперпараметры сохранились в `comet.ml`\n",
    "\n",
    "![Hyperparameters](./imgs/hyperparameters_logging.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2f175",
   "metadata": {},
   "source": [
    "### Логгирование метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e563eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, dataloader, experiment: Experiment):\n",
    "    step = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Откроем контекст в котором производится шаг обучения сети\n",
    "        # Это опционально\n",
    "        with experiment.train():\n",
    "            loss_train = 0.0\n",
    "            model.train()\n",
    "            for X, y in tqdm(dataloader):\n",
    "                X = X.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Добавим логгирование значений лосса\n",
    "                experiment.log_metric(\"TrainLoss\", loss.item(), step=step, epoch=epoch)\n",
    "                step += 1\n",
    "                loss_train += loss.item()\n",
    "        \n",
    "        # Тестирование модели\n",
    "        if epoch == 1 or epoch % 2 == 0:\n",
    "            with experiment.test():\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    size = len(dataloader.dataset)\n",
    "                    correct = 0\n",
    "                    for X, y in dataloader:\n",
    "                        X = X.to(device=device)\n",
    "                        y = y.to(device=device)\n",
    "                        pred = model(X)\n",
    "                        correct += (pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "                    acc = correct / size\n",
    "                \n",
    "                # Логирование значений точности\n",
    "                experiment.log_metric('Accuracy', acc, epoch=epoch)\n",
    "                print('{} Epoch {}, Training loss {}, Accuracy {}'.format(\n",
    "                    datetime.datetime.now(), epoch,\n",
    "                    loss_train / len(dataloader), acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83112000",
   "metadata": {},
   "source": [
    "### Подготовим все необходимое для обучения нейронной сети и запустим процесс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af912ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation((-30, 30)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed93d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', \n",
    "    download=False, \n",
    "    train=True,\n",
    "    transform=augmentation\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=hyperparameters['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=hyperparameters['num_workers']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6eeef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, n_channels: int = 1, n_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.resnet = torchvision.models.resnet18(pretrained=False)\n",
    "        # Заменим первую свертку\n",
    "        self.resnet.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Linear(in_features=self.resnet.fc.in_features, out_features=n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hx = self.resnet(x)\n",
    "        return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a150e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet18(n_channels=hyperparameters['in_channels']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f7a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=hyperparameters['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "967282a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fdd3a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:06<00:00,  9.34it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:27:57.519771 Epoch 1, Training loss 0.5988685771570368, Accuracy 0.8247833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.99it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:05.131737 Epoch 2, Training loss 0.40655929607860114, Accuracy 0.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.98it/s]\n",
      "100%|██████████| 59/59 [00:04<00:00, 11.98it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:17.645883 Epoch 4, Training loss 0.33912664500333495, Accuracy 0.8788333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.95it/s]\n",
      "100%|██████████| 59/59 [00:05<00:00, 11.77it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:30.373786 Epoch 6, Training loss 0.30487178846941154, Accuracy 0.86105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:04<00:00, 11.82it/s]\n",
      "100%|██████████| 59/59 [00:05<00:00, 11.80it/s]\n",
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:43.244678 Epoch 8, Training loss 0.28035432832725976, Accuracy 0.8845333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:05<00:00, 11.78it/s]\n",
      "100%|██████████| 59/59 [00:04<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-19 07:28:55.880353 Epoch 10, Training loss 0.2616798769114381, Accuracy 0.8946333333333333\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 10,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    dataloader = dataloader,\n",
    "    experiment = experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1015601",
   "metadata": {},
   "source": [
    "**Важно после окончания эксперимента выполнить следующий вызов метода!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41a239",
   "metadata": {},
   "source": [
    "Во время процесса обучения графики в comet.ml обновляются динамически, что позволяет нам в реальном времени следить за экспериментом (множество экспериментов на общем графике).\n",
    "Рассмотри некоторые возможности которые предоставил нам comet.ml **(заметьте, мы добавили только логирование гиперпараметров, значений ошибки во время обучения и значений метрики точности)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a1afb",
   "metadata": {},
   "source": [
    "1. Вкладка `Charts`\n",
    "\n",
    "На ней мы можем сейчас наблюдать несколько графиков (comet.ml автоматически генерирует графики из имеющихся у него данных, однако мы вольны сами настроить их отображение в случае необходимости. Настроить их подписи, вид (например bar-chart вместо графиков) и т.д.).\n",
    "\n",
    "Обратимся к рисунку.\n",
    "\n",
    "![Charts](./imgs/charts.png)\n",
    "\n",
    "На рисунке видно три графика, два из них идентичные (за исключением параметра сглаживания). Они отображают значения функции ошибки по мере обучения нейронной сети. И еще один график - на нем видно значения точности нейронной сети.\n",
    "\n",
    "2. Вкладка `Panels` \n",
    "\n",
    "Она предназначена для настройки чего-то вроде `Dashboard` где вы можете настроить детально, какую информацию выводить на экран. На рисунке ниже можно увидеть доступные view котоыре можно добавить в panels.\n",
    "\n",
    "![Panels](./imgs/panels.png)\n",
    "\n",
    "3. Вкладка `Code`\n",
    "\n",
    "После завершения эксперимента весь исполняемый код сохраняет в comet.ml. Это может быть крайне полезно для воспроизведения эксперимента. \n",
    "\n",
    "4. Вкладка `Metrics` \n",
    "\n",
    "Позволяет наблюдать за метриками в табличном представлении\n",
    "\n",
    "![Metrics](./imgs/metrics.png)\n",
    "\n",
    "6. Вкладка `GraphDefinition`\n",
    "\n",
    "Позволяет взглянуть на структуру нейронной сети, в нашем случае полезной информации там не оказалось, не смотря на то что автоматическое логгирование включено. В таких случаях можно логгировать структуру сети вручную используя метод `set_model_graph()`.\n",
    "\n",
    "7. Вкладка `Output`\n",
    "\n",
    "Показывает вывод в потоки stdout, stderr которые были произведены во время выполнения эксперимента. Может пригодиться для логгирования ошибок.\n",
    "\n",
    "8. Вкладка `System Metrics`\n",
    "\n",
    "Позволяет наблюдать за потреблением ресурсов системы, на которой происходит эксперимент. Здесь можно также заметить хорошо ли нейронная сеть утилизирует возможность GPU. \n",
    "\n",
    "9. Вкладка `Graphics`\n",
    "\n",
    "Данная вкладка может быть крайне полезна при работе с изображениями. Сюда можно добавлять вручную созданные (например через matplotlib) сложные графики или просто изображения (например результаты сегментации изображения). На следующем изображении указан пример, как использовалась данная возможность в одном из проектов по сегментации изображений.\n",
    "\n",
    "![Graphics](./imgs/graphics.png)\n",
    "\n",
    "10. Вкладка `Confusion Matrices`\n",
    "\n",
    "В настоящем примере мы не логгировали данные матрицы, однако на рисунке ниже приведен пример того, как они отображаются. Для их логгирование в объекте эксперимента также есть специальный метод.\n",
    "\n",
    "![ConfMatrix](./imgs/conf_matrix.png)\n",
    "\n",
    "11. Вкладка `Histograms`\n",
    "\n",
    "В данной вкладке можно логгировать гистограммы значений слоёв нейронной сети, Что может быть полезно при их исследовании и поиске проблем. По ним можно явно определить что происходит с весами слоёв.\n",
    "\n",
    "12. Вкладки `HTML` и `Notes`\n",
    "\n",
    "В данных вкладках удобно оставлять описания экспериментов. Вкладка `Notes` доступна для редактирования только с самого сайта. `HTML` же можно генерировать внутри кода эксперимента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18b71e",
   "metadata": {},
   "source": [
    "## Сравнение экспериментов между собой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f817652",
   "metadata": {},
   "source": [
    "Находясь в режиме `Panels` (находясь в режиме просмотра экспериментов проекта) можно видеть результаты всех (или выбранных по определенному фильтру или вручную) экспериментов. Там же можно вручную настроить графики если сгенерированные автоматически не позволяют произвести качественную оценку результатов.\n",
    "\n",
    "Далее на рисунке изображено то, как может выглядть суммарный график иллюстрирующий значение метрик IoU и DiceLoss для рядя экспериментов.\n",
    "\n",
    "![OverallBars](./imgs/overall_bars.png)\n",
    "\n",
    "На следующем рисунке отображен график динамики обучения нейронной сети в каждом эксперименте.\n",
    "\n",
    "![OverallLines](./imgs/overall_lines.png)\n",
    "\n",
    "По таким графикам удобно выбирать наилучшую модель / параметры и делать какие-либо выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe119d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
