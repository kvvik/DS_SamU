{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение и обучение моделей в TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В TensorFlow доступно два подхода к построению моделей:\n",
    "- использование низкоуровневого АПИ TensorFlow и класса Module;\n",
    "- использование высокоуровневого АПИ Keras.\n",
    "\n",
    "Рекомендуется использовать именно Keras, поскольку он избавляет разработчиков от забот написания цикла обучения, тестирование модели, сохранения и прочего. Однако рассмотрено будет оба подхода. В данной лекции фокус будет на использовании низкоуровневого API. Вручную будут написаны слои модели, функция ошибки и функция тестирования, а также цикл обучения. \n",
    "\n",
    "Высокоуровневый АПИ нередко применяется вкупе с низкоуровневым, поэтому вся информация в этой лекции крайне полезна для случаев, когда Keras не удовлетворяет всем потребностям и есть необходимость написать что-то своё.\n",
    "\n",
    "Низкоуровневый и высокоуровневый АПИ будут рассмотрены на примере задачи классификации изображений цифр из набора **Mnist**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Низкоуровневый АПИ + tf.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Mnist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет Mnist представляет собой набор черно-белых картинок рукописных цифр (0..9) размером 28x28 пикселей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5090612e20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем данные\n",
    "mean, std = np.mean(x_train), np.std(x_train)\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype('float32')\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 tf.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все (практически) модели состоят из слоёв - отдельных компонентов, производящих конкретную операцию: матричное умножение, свёртка, применение нелинейной функции и т.д. Такой подход к построению моделей позволяет делать код компактным, читабельным и легко поддерживаемым (для справки, раньше так не делали). \n",
    "\n",
    "Базовым классом для создания слоя (модуля) модели является класс Module. Напишем слой линейного преобразования - полносвязный слой. Он умножает входной вектор на матрицу и прибавляет байес (другой вектор)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.Module):\n",
    "    def __init__(self, in_d, out_d, name=None):\n",
    "        # in_d - input dimensionality\n",
    "        # out_d - output dimensionality\n",
    "        # В случае с tf.Module вызывать конструктор родительского класса обязательно! \n",
    "        super().__init__(name=name)\n",
    "        w = tf.random.normal(shape=[in_d, out_d], stddev=1./np.sqrt(in_d), dtype='float32')\n",
    "        self.w = tf.Variable(w, name='linear')\n",
    "        self.b = tf.Variable(tf.zeros(out_d, dtype='float32') * 0.1, name='bias')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return tf.matmul(x, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Linear(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.7744995   1.8459216   0.27362576 -0.5709607  -0.20550066  0.5763507\n",
      "   1.1164591   0.30397055  0.5187615  -1.6810396 ]], shape=(1, 10), dtype=float32)\n",
      "0.5604569\n"
     ]
    }
   ],
   "source": [
    "# Тестовый запуск\n",
    "x = tf.random.normal(shape=[1, 10])\n",
    "print(x)\n",
    "out = layer(x)\n",
    "print(np.std(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс tf.Module обладает целым рядом функций, упрощающих создание и обучение моделей:\n",
    "1. Коллекционирование весов модели (tf.Variable).\n",
    "2. Коллекционирование модулей.\n",
    "3. Возможность сохранения весов (будет показано далее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias:0\n",
      "linear:0\n"
     ]
    }
   ],
   "source": [
    "# Веса\n",
    "print(layer.variables[0].name)\n",
    "print(layer.variables[1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модули\n",
    "layer.submodules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для иллюстрации второй функции напишем слой, совмещающий в себе слой Linear и функцию активации ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReLU(tf.Module):\n",
    "    def __init__(self, in_d, out_d, name=None):\n",
    "        # in_d - input dimensionality\n",
    "        # out_d - output dimensionality\n",
    "        super().__init__(name=name)\n",
    "        linear_name = None\n",
    "        if name is not None:\n",
    "            linear_name = name + '_linear'\n",
    "        self.linear = Linear(in_d, out_d, name=linear_name)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.linear(x)\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_relu = LinearReLU(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias:0\n",
      "linear:0\n"
     ]
    }
   ],
   "source": [
    "# Веса\n",
    "print(linear_relu.variables[0].name)\n",
    "print(linear_relu.variables[1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.Linear at 0x7f508e4f8280>,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модули\n",
    "linear_relu.submodules\n",
    "# Объект `linear_relu` \"запомнил\" модуль, что находится внутри него."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим теперь двухслойную полносвязную нейронную сеть с использованием написанных слоёв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(tf.Module):\n",
    "    def __init__(self, in_d, dim=256, n_classes=10, name='neural_network'):\n",
    "        super().__init__(name=name)\n",
    "        self.input_layer = LinearReLU(in_d, dim, name='input')\n",
    "        self.classification_head = Linear(dim, n_classes, name='head')\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.classification_head(x)\n",
    "        return tf.nn.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(in_d=28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.28278467, 0.07786416, 0.03850088, 0.0468896 , 0.08967251,\n",
       "        0.09703497, 0.07453809, 0.03147001, 0.08553318, 0.17571196]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейронные сети обучаются при помощи алгоритма градиентного спуска. Определяется функция ошибки, которая далее минимизируется посредством вычитания из весов нейронной сети их градиента. Однако вручную реализовывать данный алгоритм не придётся, поскольку TensorFlow реализует его за нас. На данном этапе заботой разработчика является определение функции ошибки, написание цикла обучения и функции тестирования модели.\n",
    "\n",
    "Функция ошибки - некая скалярная дифференцируемая функция, что является мерой ошибки ответа сети. Посредством алгоритма градиентного спуска веса нейронной сети изменяются таким образом, чтобы минимизировать значение функции ошибки.\n",
    "\n",
    "В цикле обучения происходит непосредственно обучение. На каждой итерации производится один градиентный шаг (одна итерация изменения весов для минимизации функции ошибки) и каждые N итераций проходит тестирование модели.\n",
    "\n",
    "Тестирование модели по ходу обучения необходимо для того, чтобы регулировать гиперпараметры модели (и не только), дабы добиться наивысшей точности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала напишем функцию тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.63.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Функции обучения и тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Позволяет видеть виджет прогресса цикла.\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    eq = tf.cast(y_true == y_pred, 'float32')\n",
    "    return tf.reduce_mean(eq)\n",
    "\n",
    "\n",
    "def evaluate(model, x_test, y_test, batch_size=128):\n",
    "    \"\"\"\n",
    "    Функция тестирования модели.\n",
    "    \"\"\" \n",
    "    n_batches = x_test.shape[0] // batch_size\n",
    "    n_remains = x_test.shape[0] - n_batches * batch_size\n",
    "    \n",
    "    y_preds = []\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        x_batch = x_test[i*batch_size:(i+1)*batch_size]\n",
    "        # preds - [batch_size, n_classes]\n",
    "        preds = model(x_batch)\n",
    "        # preds - [batch_size]\n",
    "        preds = tf.argmax(preds, axis=-1)  # Находит индекс наибольшего элемента\n",
    "        y_preds.append(preds)\n",
    "    \n",
    "    if n_remains != 0:\n",
    "        x_batch = x_test[-n_remains:]\n",
    "        preds = model(x_batch)\n",
    "        preds = tf.argmax(preds, axis=-1)\n",
    "        y_preds.append(preds)\n",
    "    \n",
    "    y_preds = tf.concat(y_preds, axis=0)\n",
    "    return accuracy(y_test, y_preds).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 636.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность 6.98 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, x_test, y_test)\n",
    "print('Точность', round(acc * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность крайне низкая, что в целом ожидаемо, поскольку модель еще не обучена. Напишем теперь функцию, что производит одну обучающую итерацию (один обучающий шаг)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "\n",
    "\n",
    "def cross_entropy(labels, preds):\n",
    "    \"\"\"\n",
    "    Вычисляет значение перекрестной энтропии (Cross-Entropy) - классическая\n",
    "    функция ошибки, используемая в задаче классификации.\n",
    "    \"\"\"\n",
    "    # Прибавление константы для улучшения численной стабильности.\n",
    "    # Если не прибавлять маленькое чисто, то возможно появление nan\n",
    "    log = tf.math.log(preds + 1e-4)\n",
    "    onehot = tf.one_hot(labels, depth=N_CLASSES, dtype='float32')\n",
    "    log = log * onehot\n",
    "    log = tf.reduce_sum(log, axis=-1)\n",
    "    return -tf.reduce_mean(log)\n",
    "\n",
    "\n",
    "def train_step(model, data, optim):\n",
    "    \"\"\"\n",
    "    Функция, производящая один обучающий шаг.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # \"Прогон\" данных через модель и вычисление значения функции ошибки\n",
    "        x, y = data\n",
    "        preds = model(x)\n",
    "        loss = cross_entropy( y, preds)\n",
    "    # Вычисление градиентов\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    # Применение градиентов к весам\n",
    "    optim.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше используется функция ошибки Cross Entropy (перекрёстная энтропия), что является стандартом для задачи классификации. Функция `train_step` содержит в себе стандартный код для всех циклов обучения:\n",
    "1. прогонка данных через модель;\n",
    "2. вычисление значения функции ошибки;\n",
    "3. вычисление градиентов весов;\n",
    "4. применение градиентов к весам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Цикл обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры обучения\n",
    "\n",
    "optim = tf.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "n_batches = x_train.shape[0] // BATCH_SIZE\n",
    "print_period = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Эпоха (`EPOCHS`) - означает один проход по всему датасету. \n",
    "- Размер батча (`BATCH_SIZE`) - группа экземпляров (картинок) данных, что подаётся на вход модели. Вместо того, чтобы в модель подавать лишь один экземпляр, обычно подаётся несколько экземпляров, что и называют батчем. Связано это с тем, что градиент, вычисляемый по одному экземпляру, очень шумный, из-за чего обучение проходит гораздо медленнее. Такой подход также не позволяет эффективно утилизировать вычислители (графический процессор). Поэтому обычно считают градиент по батчу, усредняя его.\n",
    "- Оптимизатор (`optim`) - алгоритм градиентного спуска или его модификация. Поскольку классический градиентный спуск сходится довольно медленно, было разработано множество модификаций (например, Adam). Они сходятся существенно быстрее, позволяя добиться высокой точности при меньших затратах времени. Заметка: за классический градиентный спуск отвечает оптимизатор `tf.optimizers.SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/234 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iteration: 0 Loss: 2.748917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 115/234 [00:01<00:01, 109.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iteration: 100 Loss: 0.16372028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 221/234 [00:02<00:00, 112.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iteration: 200 Loss: 0.11518546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 108.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 524.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 13/234 [00:00<00:01, 122.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 0 Loss: 0.091917574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 114/234 [00:01<00:01, 104.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 100 Loss: 0.20321853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 217/234 [00:01<00:00, 107.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 200 Loss: 0.050820768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 112.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 516.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/234 [00:00<00:03, 68.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Iteration: 0 Loss: 0.07302175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 121/234 [00:01<00:01, 107.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Iteration: 100 Loss: 0.057514787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 212/234 [00:02<00:00, 101.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Iteration: 200 Loss: 0.12362762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 102.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 437.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Accuracy: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10/234 [00:00<00:02, 91.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Iteration: 0 Loss: 0.04792975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 115/234 [00:01<00:01, 116.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Iteration: 100 Loss: 0.096027955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 221/234 [00:01<00:00, 118.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Iteration: 200 Loss: 0.08608166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 110.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 565.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Accuracy: 0.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/234 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Iteration: 0 Loss: 0.021222575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 117/234 [00:01<00:01, 85.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Iteration: 100 Loss: 0.044168565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 214/234 [00:02<00:00, 111.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Iteration: 200 Loss: 0.050489713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:02<00:00, 103.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 585.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Accuracy: 0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Цикл обучения\n",
    "\n",
    "take_data = lambda i: (x_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE], y_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Перемешивание данных. Очень часто это позволяет повысить точность модели.\n",
    "    # Рекомендуется перемешивать данные всегда!\n",
    "    indices = np.arange(0, len(x_train), 1)\n",
    "    np.random.shuffle(indices)\n",
    "    x_train, y_train = x_train[indices], y_train[indices]\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        data = take_data(i)\n",
    "        loss = train_step(model, data, optim)\n",
    "        \n",
    "        if i % print_period == 0:\n",
    "            print('Epoch:', epoch, 'Iteration:', i, 'Loss:', loss.numpy())\n",
    "    \n",
    "    print('Тестирование модели...')\n",
    "    acc = evaluate(model, x_test, y_test)\n",
    "    print('Epoch:', epoch, 'Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 573.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговая точность модели: 0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, x_test, y_test)\n",
    "print('Итоговая точность модели:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Сохранение весов модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В TensorFlow есть два способа сохранить веса обученной модели:\n",
    "1. [Checkpoint (чекпоинт)](https://www.tensorflow.org/guide/checkpoint);\n",
    "2. [SavedModel](https://www.tensorflow.org/guide/saved_model).\n",
    "    \n",
    "**Чекпоинты** полезны для случаев, когда возможно дообучение модели или её части. В файл сохраняются ТОЛЬКО веса модели, вычислительный граф не сохраняется. То есть необходимо где-то отдельно сохранить исходный код модели.\n",
    "\n",
    "**SavedModel** полезна для подготовки модели к деплоингу в бизнес-решение. В данном случае сохраняются не только веса, но и сам вычислительный граф - в файл записывается полноценная TensorFlow программа, которую можно в дальнейшем запустить где угодно, наличие исходного кода модели не требуется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_weights-1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.save('model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 475.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До загрузки весов: 0.0586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 539.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После загрузки весов: 0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Создадим модель вновь и загрузим в нее веса\n",
    "model2 = NN(28*28)\n",
    "\n",
    "print('До загрузки весов:', evaluate(model2, x_test, y_test))\n",
    "\n",
    "ckpt2 = tf.train.Checkpoint(model=model2)\n",
    "ckpt2.restore('model_weights-1')\n",
    "\n",
    "print('После загрузки весов:', evaluate(model2, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Особенность SavedModel состоит в том, что данный формат сохраняет именно TensorFlow программу - статический вычислительный граф. Чтобы построить статический граф в TensorFlow 2.x необходимо использовать [tf.function](https://www.tensorflow.org/guide/function). tf.function требует отдельного внимания, однако на данный момент достаточно сказать, что эта функция \"запоминает\" выполненный TensorFlow код и компилирует его в статический граф, который после можно использовать отдельно от исходного кода модели.\n",
    "\n",
    "Чтобы сохранить модель, нужно внести одно небольшое изменение в ее код - обернуть метод call декоратором tf.function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(tf.Module):\n",
    "    def __init__(self, in_d, dim=256, n_classes=10, name='neural_network'):\n",
    "        super().__init__(name=name)\n",
    "        self.input_layer = LinearReLU(in_d, dim, name='input')\n",
    "        self.classification_head = Linear(dim, n_classes, name='head')\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 28*28], dtype='float32', name='input')])\n",
    "    def __call__(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.classification_head(x)\n",
    "        return tf.nn.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = NN(28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(1, 28*28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 ms, sys: 9.34 ms, total: 34.7 ms\n",
      "Wall time: 30.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.11663068, 0.0729905 , 0.29678458, 0.04315365, 0.17496988,\n",
       "        0.05506885, 0.03072948, 0.12057099, 0.07311395, 0.01598745]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# После вызова tf.function скомпилирует исполненный код в статический граф.\n",
    "model3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 ms, sys: 0 ns, total: 2.96 ms\n",
      "Wall time: 2.27 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.11663068, 0.0729905 , 0.29678458, 0.04315365, 0.17496988,\n",
       "        0.05506885, 0.03072948, 0.12057099, 0.07311395, 0.01598745]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Можно заметить, что последующие вызовы происходят существенно быстрее.\n",
    "model3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model3, 'saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_loaded = tf.saved_model.load('saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.11663068, 0.0729905 , 0.29678458, 0.04315365, 0.17496988,\n",
       "        0.05506885, 0.03072948, 0.12057099, 0.07311395, 0.01598745]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_loaded(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. tf.data и датасеты в TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше вручную был написан весь код для итерации по датасету. Если придется добавлять какую-либо агументацию данных, то задача сильно усложнится. В TensorFlow уже есть готовые инструменты по организации работы с данными, а именно: [tf.data АПИ](https://www.tensorflow.org/guide/data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
